{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93c7719",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "\n",
    "We need to predict whether a customer will leave the bank soon. You have the data on clients’ past behavior and termination of contracts with the bank.\n",
    "\n",
    "Build a model with the maximum possible F1 score. To pass the project, you need an F1 score of at least 0.59. Check the F1 for the test set.\n",
    "\n",
    "Additionally, measure the AUC-ROC metric and compare it with the F1.\n",
    "\n",
    "#### Business Statement\n",
    "One of the key business metrics (along with cash flow etc.) for banks, internet providers, pay TV companies, telecom companies is customer attrition analysis (or customer churn analysis). We say customer churn is loss of clients or customers. It is cheaper to keep existing customers than go for new ones. Beta bank have already seen the effect of customer churn as it affects their end of the year revenue and monthly recurring revenue (or MRR). To this end, we need to predict whether a customer will leave a bank soon given their past relationship and behavior while operating with Beta bank. The bank hopes to deploy churn prediction models and effective retention strategies in managing customer attrition thereby preventing significant loss of revenue from defecting customers.\n",
    "\n",
    "#### Task Statement\n",
    "Using the customer data, train a model that predicts whether a customer will leave the bank soon.\n",
    "\n",
    "## Data description\n",
    "The data can be found in '/datasets/Churn.csv' file. Download the dataset.\n",
    "\n",
    "### Features\n",
    "\n",
    "- RowNumber — data string index\n",
    "- CustomerId — unique customer identifier\n",
    "- Surname — surname\n",
    "- CreditScore — credit score\n",
    "- Geography — country of residence\n",
    "- Gender — gender\n",
    "- Age — age\n",
    "- Tenure — period of maturation for a customer’s fixed deposit (years)\n",
    "- Balance — account balance\n",
    "- NumOfProducts — number of banking products used by the customer\n",
    "- HasCrCard — customer has a credit card\n",
    "- IsActiveMember — customer’s activeness\n",
    "- EstimatedSalary — estimated salary\n",
    "\n",
    "#### Target\n",
    "\n",
    "- Exited — сustomer has left\n",
    "\n",
    "### Objectives\n",
    "The objectives of this project are to:\n",
    "\n",
    "- Develop a model that would predict whether a customer will leave the bank soon\n",
    "- Build a machine learning model with the maximum possible F1 score of atleast 0.59 or higher.\n",
    "- Measure the AUC-ROC metric and compare it with the F1 score.\n",
    "\n",
    "## Open the data file and study the general information\n",
    "We require the following libraries: pandas and numpy for data preprocessing and manipulation, Scikit-Learn for building our learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2747d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project libraries has been successfully been imported!\n"
     ]
    }
   ],
   "source": [
    "# import pandas and numpy for data preprocessing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import train_test_split to split data\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.options.mode.chained_assignment = None # to avoid SettingWithCopyWarning after scaling\n",
    "\n",
    "# import machine learning module from the sklearn library\n",
    "from sklearn.dummy import DummyClassifier # import dummy classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression # import logistic regression \n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier # import adaboost classifier algorithm\n",
    "from catboost import CatBoostClassifier # import catboost classifier\n",
    "\n",
    "# import metrics for sanity check on model\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import sklearn utilities\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print('Project libraries has been successfully been imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2638dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been read correctly!\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "try:\n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('C:/Users/tresselg/Desktop/Data\\ Science\\ Work/Praktikum/Supervised\\ Learning/Project/Churn.csv')\n",
    "print('Data has been read correctly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a154707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine if columns in file have null values\n",
    "def get_percent_of_na(df, num):\n",
    "    count = 0\n",
    "    df = df.copy()\n",
    "    s = (df.isna().sum() / df.shape[0])\n",
    "    for column, percent in zip(s.index, s.values):\n",
    "        num_of_nulls = df[column].isna().sum()\n",
    "        if num_of_nulls == 0:\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "        print('Column {} has {:.{}%} percent of Nulls, and {} of nulls'.format(column, percent, num, num_of_nulls))\n",
    "    if count != 0:\n",
    "        print(\"\\033[1m\" + 'There are {} columns with NA.'.format(count) + \"\\033[0m\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"\\033[1m\" + 'There are no columns with NA.' + \"\\033[0m\")\n",
    "        \n",
    "# function to display general information about the dataset\n",
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    This function uses the head(), info(), describe(), shape() and duplicated() \n",
    "    methods to display the general information about the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\033[1m\" + '-'*100 + \"\\033[0m\")\n",
    "    print('Head:')\n",
    "    print()\n",
    "    display(df.head())\n",
    "    print('-'*100)\n",
    "    print('Info:')\n",
    "    print()\n",
    "    display(df.info())\n",
    "    print('-'*100)\n",
    "    print('Describe:')\n",
    "    print()\n",
    "    display(df.describe())\n",
    "    print('-'*100)\n",
    "    display(df.describe(include='object'))\n",
    "    print()\n",
    "    print('Columns with nulls:')\n",
    "    display(get_percent_of_na(df, 4))  # check this out\n",
    "    print('-'*100)\n",
    "    print('Shape:')\n",
    "    print(df.shape)\n",
    "    print('-'*100)\n",
    "    print('Duplicated:')\n",
    "    print(\"\\033[1m\" + 'We have {} duplicated rows.\\n'.format(df.duplicated().sum()) + \"\\033[0m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e8984c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information about the dataframe\n",
      "\u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "Head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Describe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>2932</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>Smith</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>32</td>\n",
       "      <td>5014</td>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surname Geography Gender\n",
       "count    10000     10000  10000\n",
       "unique    2932         3      2\n",
       "top      Smith    France   Male\n",
       "freq        32      5014   5457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with nulls:\n",
      "Column Tenure has 9.0900% percent of Nulls, and 909 of nulls\n",
      "\u001b[1mThere are 1 columns with NA.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Shape:\n",
      "(10000, 14)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Duplicated:\n",
      "\u001b[1mWe have 0 duplicated rows.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# study the general information about the dataset \n",
    "print('General information about the dataframe')\n",
    "get_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fa71a",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "From the information about the dataset, we have 10000 rows and 14 features. Looking at the dataset, we can see that about 9% of the data is missing in the Tenure column. We should also note that the missing values are missing at random (MAR). To handle these missing values, we could either drop them entirely since the percentage of missing values is less than 10% or replace them by the median of the column. We also need to correct the datatype from float to int in the Tenure, Balance and EstimatedSalary columns.\n",
    "\n",
    "\n",
    "## Prepare the data\n",
    "\n",
    "#### Processing Missing Values\n",
    "\n",
    "#### Prepare Tenure column\n",
    "\n",
    "To replace missing values in the Tenure column, we first get the unique values of Surname, then get the list of possible Tenure for those names. We then choose a random value from the list (excluding the nan values) and assign that to the missing tenure for that surname in the dataframe. For unique surname with an empty list, we use the median of the value in the Tenure column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff1eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in the Tenure column\n",
    "# get unique values of name from this dataframe\n",
    "for surname in df['Surname'].unique().tolist():\n",
    "    # get specific 'Surname' possible Tenure\n",
    "    specific_surname_df = df[df['Surname'] == surname].dropna()['Tenure']\n",
    "    surname_tenure_list = specific_surname_df.unique().tolist()\n",
    "    # for the missing values, assign a random choice of the tenure for that surname. The default is the median of the 'Tenure'\n",
    "    if surname_tenure_list != []:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = random.choice(surname_tenure_list)\n",
    "    else:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = df['Tenure'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934f4b1",
   "metadata": {},
   "source": [
    "We have replaced missing values in the Tenure column based on the condition we specified. Let's look at the statistics of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e802ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.008900</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.875595</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.008900   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.875595   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the statistics of the new dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4132aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82024af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to the correct data type\n",
    "def convert_to_type(df, cols, type_val):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(type_val)\n",
    "        \n",
    "convert_to_type(df, ['Surname', 'Geography', 'Gender'], str)\n",
    "convert_to_type(df, ['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Exited'], 'int64')\n",
    "convert_to_type(df, ['Balance', 'EstimatedSalary'], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c3d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1dfdcc",
   "metadata": {},
   "source": [
    "Now we don't have any missing values and we have changed the datatype in the dataset. Replacing the missing values seems like a better option than dropping the columns with missing values. Care should be taken when replacing missing values. We don't want to create bias or variance in our dataset. The data has been cleaned and so it is ready for feature engineering and machine learning.\n",
    "\n",
    "## Feature engineering\n",
    "#### Feature preparation\n",
    "In this section, we carry out feature engineering and one-hot encoding for the categorical features. We will use one-hot encoding to transform categorical features to numerical features. To do that we have to first create dummy variable and then apply one-hot encoding for categorical features. First, we drop unimportant features like CustomerId, RowNumber and Surname from the dataframe before proceeding with one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6bc02ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unimportant features\n",
    "df = df.drop(['CustomerId', 'RowNumber', 'Surname'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa6ce233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set now contains 7000 observations representing 70% of the data\n",
      "The test set now contains 3000 observations representing 30% of the data\n",
      "\n",
      "\u001b[1mShape of features and target\u001b[0m\n",
      "------------------------------\n",
      "Train features : (7000, 11)\n",
      "Train target   : (7000,)\n",
      "Test features  : (3000, 11)\n",
      "Test target    : (3000,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9716</td>\n",
       "      <td>1.658077</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>-0.017183</td>\n",
       "      <td>0.635477</td>\n",
       "      <td>2.527132</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>1.480907</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.198643</td>\n",
       "      <td>0.584111</td>\n",
       "      <td>0.332462</td>\n",
       "      <td>0.375870</td>\n",
       "      <td>-0.895510</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>0.153167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>-1.374648</td>\n",
       "      <td>0.774530</td>\n",
       "      <td>0.332462</td>\n",
       "      <td>1.302947</td>\n",
       "      <td>0.815811</td>\n",
       "      <td>-1.549099</td>\n",
       "      <td>-1.046809</td>\n",
       "      <td>0.817773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7507</td>\n",
       "      <td>-0.784664</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>1.381396</td>\n",
       "      <td>0.696496</td>\n",
       "      <td>-0.895510</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>-1.046809</td>\n",
       "      <td>0.329403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>2.051400</td>\n",
       "      <td>2.583513</td>\n",
       "      <td>-0.366827</td>\n",
       "      <td>-1.222967</td>\n",
       "      <td>0.815811</td>\n",
       "      <td>-1.549099</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>-0.617269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "9716     1.658077  0.012853 -0.017183  0.635477       2.527132   0.645536   \n",
       "224      0.198643  0.584111  0.332462  0.375870      -0.895510   0.645536   \n",
       "589     -1.374648  0.774530  0.332462  1.302947       0.815811  -1.549099   \n",
       "7507    -0.784664  0.488901  1.381396  0.696496      -0.895510   0.645536   \n",
       "1457     2.051400  2.583513 -0.366827 -1.222967       0.815811  -1.549099   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "9716        0.955284         1.480907                  1                0   \n",
       "224         0.955284         0.153167                  1                0   \n",
       "589        -1.046809         0.817773                  0                1   \n",
       "7507       -1.046809         0.329403                  1                0   \n",
       "1457        0.955284        -0.617269                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "9716            1  \n",
       "224             1  \n",
       "589             0  \n",
       "7507            1  \n",
       "1457            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one-hot encoding of categorical features\n",
    "df_ohe = pd.get_dummies(df, drop_first=True) \n",
    "    \n",
    "# declare variables for features and target\n",
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop(['Exited'], axis=1)\n",
    "    \n",
    "# split data into training and testing \n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.30, random_state=12345\n",
    ")\n",
    "\n",
    "# display the shape of the split dataset\n",
    "print('The train set now contains {}'.format(features_train.shape[0]) + ' observations representing 70% of the data')\n",
    "print('The test set now contains {}'.format(features_test.shape[0]) + ' observations representing 30% of the data')\n",
    "print()\n",
    "\n",
    "# numeric features in dataset\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', \n",
    "           'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# features scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "# transform the training set and the test set using transform()\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_test[numeric]  = scaler.transform(features_test[numeric])\n",
    "    \n",
    "print(\"\\033[1m\" + 'Shape of features and target' + \"\\033[0m\")\n",
    "print('-'*30)\n",
    "print('Train features :', features_train.shape)\n",
    "print('Train target   :',target_train.shape)\n",
    "print('Test features  :',features_test.shape)\n",
    "print('Test target    :',target_test.shape)\n",
    "print()\n",
    "display(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca458a18",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We encoded the categorical feature using one-hot encoding. By now, we have a lot of data from the one-hot encoding process. But when data is abundant, we have a chance of falling into the dummy feature trap. If we keep the features as they are now, it will hinder the training process. We have added 3 new features to our table from the one-hot encoding process, but their high correlation will confuse our model. To avoid this, we can safely remove any one column, since its values can be easily inferred from one of the other two columns (it has 1 where the other two columns have zeroes, and it has zeroes everywhere else). This way, we will not fall into the dummy trap. Pandas library has a function pd.get_dummies() that can be used for getting dummy variables. We split the data two ways into 70% training set, and 30% testing sets. Since the features have different scales, we standardized the numerical features of the data. The size of the new table is 7000 rows and 11 columns for the train features set, and 3000 rows and 11 columns for the test features set. Now the data is prepared and ready for analysis.\n",
    "\n",
    "## Examine the balance of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cb432d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037\n",
      "7963\n"
     ]
    }
   ],
   "source": [
    "#First, let's look at the class imbalance (if there is any) briefly:\n",
    "print(df[df['Exited'] == 1]['Exited'].count())\n",
    "print(df[df['Exited'] == 0]['Exited'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a65cd",
   "metadata": {},
   "source": [
    "Clearly, there is an apparent imbalance, almost a 1:4 ratio. Now, let's see how much this affects our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c839b0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8026666666666666\n",
      "f1 score: 0.308411214953271\n",
      "AUC: 0.7575511868457814\n"
     ]
    }
   ],
   "source": [
    "#Let's pretend like we don't know anything about class imbalance:\n",
    "LogRegModImb = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "LogRegModImb.fit(features_train,target_train)\n",
    "print('Accuracy', LogRegModImb.score(features_test, target_test))\n",
    "print('f1 score:' ,f1_score(target_test, LogRegModImb.predict(features_test)))\n",
    "print('AUC:', roc_auc_score(target_test, LogRegModImb.predict_proba(features_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43a05d",
   "metadata": {},
   "source": [
    "We have a accuracy of 0.80, f1 score of 0.31, and AUC of 0.76 when we do not account for imbalance and use logistic regression. We don't need to check Random Forest and Decision Tree because if the imbalance affects the results of Logistic Regression, it will naturally affect the results of Random Forest and Decision Tree since they do not perform well on imbalanced data sets.\n",
    "\n",
    "Now, let's balance the data and see how the logistic regression improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b9de4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7026666666666667\n",
      "f1 score: 0.4949037372593431\n",
      "AUC: 0.7619418029720265\n"
     ]
    }
   ],
   "source": [
    "LogRegModBal = LogisticRegression(solver='liblinear', random_state=12345, class_weight='balanced')\n",
    "LogRegModBal.fit(features_train,target_train)\n",
    "print('Accuracy', LogRegModBal.score(features_test, target_test))\n",
    "print('f1 score:' ,f1_score(target_test, LogRegModBal.predict(features_test)))\n",
    "print('AUC:',roc_auc_score(target_test, LogRegModBal.predict_proba(features_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc7a04",
   "metadata": {},
   "source": [
    "We have a accuracy of 0.70, f1 score of 0.47, and AUC of 0.76 when we do account for imbalance and use logistic regression. The accuracy has gone down from balancing but the f1 score has improved.\n",
    "\n",
    "Now that we know the impact of balancing, let's proceed with some strategies to account for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4b0ec",
   "metadata": {},
   "source": [
    "In this section, we trained the model with taking into account the imbalance. We achieved an F1 score of 0.47. Next we try to improve the quality of the model using two different approaches to fixing class imbalance.\n",
    "\n",
    "## Improve the quality of the model\n",
    "We apply two different approaches to fix the class imbalance.\n",
    "\n",
    "- Class weight adjustment\n",
    "- Upsampling\n",
    "\n",
    "#### Using Class Weight Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e33e74bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with adjusted class weight: 0.495\n"
     ]
    }
   ],
   "source": [
    "# class weight adjustment\n",
    "model = LogisticRegression(random_state=12345, class_weight='balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "test_predictions = model.predict(features_test) \n",
    "print('F1 score with adjusted class weight: {:.3f}'.format(f1_score(target_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa6de88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.62\n",
      "1    0.38\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check after class imbalance\n",
    "test_predictions = pd.Series(model.predict(features_test))\n",
    "class_frequency = test_predictions.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74af425",
   "metadata": {},
   "source": [
    "Here, we made the rare classes weigh more by specifying class_weight='balanced'. Notice how the F1 score increased to $\\approx$ 0.496 for a balanced class.\n",
    "\n",
    "#### By Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a06bf933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform upsampling \n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# new training set created\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2110555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score after upsampling: 0.485\n"
     ]
    }
   ],
   "source": [
    "# F1 score after upsampling \n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "test_predictions = model.predict(features_test) \n",
    "print('F1 score after upsampling: {:.3f}'.format(f1_score(target_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0fdcf",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "First, we split the training sample into negative and positive observations, we duplicated the positive observations and combine them with the negative class observation. Then we shuffled the data using shuffle() function, and trained our LogisticRegression model with the new data. We calculated the F1 score to be $\\approx$ 0.487. This is an improvement from the default F1 score of 0.304 calculated initially. This shows an improvement in the F1 score when the class is balanced.\n",
    "\n",
    "## Investigate different models quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4322b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot ROC curve\n",
    "def plot_roc(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        \"\"\"\n",
    "        This function plots the ROC curve\n",
    "        \"\"\"\n",
    "        if not ax: fig, ax = plt.subplots(1, 1)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "        ax.plot([0, 1], [0, 1],'r--')\n",
    "        ax.plot(fpr, tpr, lw=2, label=label)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_title(\n",
    "            'ROC curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(fpr, tpr):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('False Positive Rate (FPR)')\n",
    "        ax.set_ylabel('True Positive Rate (TPR)')\n",
    "        ax.annotate(f'AUC: {auc(fpr, tpr):.2}', xy=(.43, .025))\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax\n",
    "    \n",
    "# function to plot the precision-recall curve\n",
    "def plot_pr(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        \"\"\"\n",
    "        This function is used to the precision-recall curve \n",
    "        \"\"\"\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "        if not ax: fig, ax = plt.subplots()\n",
    "        ax.plot([0, 1], [1, 0],'r--')    \n",
    "        ax.plot(recall, precision, lw=2, label=label)\n",
    "        ax.legend()\n",
    "        ax.set_title(\n",
    "            'Precision-recall curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(recall, precision):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_xlim(-0.05, 1.05)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41b588",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "We are going to try and tune the hyperparameters of the following classification algorithms. A small grid searching example is given and used as a starting point for the investigation. To speed up running this section, it is best if the code is run in google colab using google's GPU.\n",
    "\n",
    "#### Decision Tree Classifier\n",
    "For the decision tree classifier, we iterate over different values and compare the quality of the model by tuning the max_depth hyperparameter. In GridSearchCV, we pass scoring='f1' to tune the target metric which is the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95b24376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best F1 score is : \n",
      "{'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 16}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.558\n",
      "The accuracy of the model against the training data is: 0.643\n",
      "F1 score:  0.5413826679649465\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization for Decision tree classifier\n",
    "parameters = {\n",
    "    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"max_depth\" : [2, 4, 8, 16],\n",
    "    \"min_samples_split\" : [2, 4, 8, 16],\n",
    "    \"min_samples_leaf\" : [2, 4, 6]\n",
    "    }\n",
    "classifier = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(classifier, parameters, scoring='f1', cv=5)\n",
    "grid.fit(features_train, target_train) \n",
    "y_pred = grid.predict(features_test)\n",
    "print('The parameters combination that would give best F1 score is : ')\n",
    "print(grid.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid.best_score_))\n",
    "print('The accuracy of the model against the training data is: {:.3f}'.format(grid.score(features_train, target_train)))\n",
    "print('F1 score: ', f1_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73f20210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decision tree classifier\n",
    "def decision_tree_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a decision tree classifier function developed to train  \n",
    "    the model, make prediction on train and testing dataset, print\n",
    "    the F1 score and model accuracy for training and testing datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "    model = DecisionTreeClassifier(**grid.best_params_) \n",
    "    model.fit(X_train, y_train) # train the model\n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on testing set\n",
    "    dt_test_predictions = model.predict(X_test) \n",
    "    dt_test_predictions_acc = accuracy_score(y_test, dt_test_predictions)\n",
    "    test_scores.append(dt_test_predictions_acc)\n",
    "    f1_score_ = f1_score(y_test, dt_test_predictions)\n",
    "    f1_scores.append(f1_score_)\n",
    "    scores = list(zip(f1_scores, train_scores, test_scores))\n",
    "    print('The decision tree classifier had the best ' \"\\033[1m\" + 'F1 score of {:.3f}'.format(max(scores, key = lambda x: x[0])[0]) + \"\\033[0m\" +   \n",
    "          ' and accuracy of ' \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[1]) + ' for the training set' + \"\\033[0m\" + \n",
    "          ' and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[2]) + ' for the testing set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate decision tree classifier metric\n",
    "    print_model_evaluation(target_test, dt_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a1a2bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree classifier had the best \u001b[1mF1 score of 0.541\u001b[0m and accuracy of \u001b[1m87.97% for the training set\u001b[0m and \u001b[1m84.30% for the testing set\u001b[0m\n",
      "\n",
      "\u001b[1mF1 score: \u001b[0m 0.541\n",
      "\u001b[1mAccuracy Score: \u001b[0m 84.30%\n",
      "\u001b[1mPrecision: \u001b[0m 0.693\n",
      "\u001b[1mRecall: \u001b[0m 0.444\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 69.61%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 69.61%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2251  123]\n",
      " [ 348  278]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      2374\n",
      "           1       0.69      0.44      0.54       626\n",
      "\n",
      "    accuracy                           0.84      3000\n",
      "   macro avg       0.78      0.70      0.72      3000\n",
      "weighted avg       0.83      0.84      0.83      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine F1 score for decision tree classifier\n",
    "decision_tree_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12348661",
   "metadata": {},
   "source": [
    "We used GridSearchCV to carry out hyperparameter optimization on the max_depth, criterion, min_samples_split, and min_samples_leaf parameters. We looking for the best parameter setting for our decision tree classifier. We note that shallow decision trees (e.g. few depth) generally do not overfit but have poor performance (high bias, low variance), and deep trees (e.g. high depth) generally do overfit and have good performance (low bias, high variance). Our desirable tree depth is one that is not so shallow that it has low performance and not so deep that it overfits the training dataset. We need to have a balance between bias and variance - bias variance tradeoff. At max_depth of 8, we have an F1 score of 0.54, an accuracy of 87.90% for the training set, and 84.53% for the testing set.\n",
    "\n",
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "023b7d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best F1 score is : \n",
      "{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.326\n",
      "The accuracy of the model against the training data is: 0.330\n",
      "F1 score:  0.3064327485380117\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization\n",
    "# define parameters\n",
    "grid = {\n",
    "    \"solver\" : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    \"penalty\" : ['l2'],\n",
    "    \"C\" : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "# define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the model\n",
    "regressor = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = regressor, param_grid = grid, \n",
    "                           n_jobs=-1, cv=cv, scoring='f1', error_score=0)\n",
    "grid_search.fit(features_train, target_train) \n",
    "y_pred = grid_search.predict(features_test)\n",
    "print('The parameters combination that would give best F1 score is : ')\n",
    "print(grid_search.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid_search.best_score_))\n",
    "print('The accuracy of the model against the training data is: {:.3f}'.format(grid_search.score(features_train, target_train)))\n",
    "print('F1 score: ', f1_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "426f6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and testing dataset, \n",
    "    and print F1 score and evaluation metrics for testing datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "    model = LogisticRegression(**grid_search.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on testing set\n",
    "    lr_test_predictions = model.predict(X_test) \n",
    "    lr_test_predictions_acc = accuracy_score(y_test, lr_test_predictions)\n",
    "    test_scores.append(lr_test_predictions_acc)\n",
    "    f1_score_ = f1_score(y_test, lr_test_predictions)\n",
    "    f1_scores.append(f1_score_)\n",
    "    scores = list(zip(f1_scores, train_scores, test_scores))\n",
    "    print('The logistic regression classifier had the best ' \"\\033[1m\" + \n",
    "          'F1 score of {:.3f} '.format(max(scores, key = lambda x: x[0])[0]) + \"\\033[0m\" + \n",
    "          'using' \"\\033[1m\" + ' C parameter of {},'.format(grid_search.best_params_['C']) + \"\\033[0m\" +\n",
    "          \"\\033[1m\" + ' {} as logistic regression solver'.format(grid_search.best_params_['solver']) + \"\\033[0m\" +\n",
    "          ' leading to an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[0])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[2]) + ' for the testing set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate logistic regression classifier metric\n",
    "    print_model_evaluation(target_test, lr_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62af8067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic regression classifier had the best \u001b[1mF1 score of 0.306 \u001b[0musing\u001b[1m C parameter of 10,\u001b[0m\u001b[1m liblinear as logistic regression solver\u001b[0m leading to an accuracy of \u001b[1m81.49% for the training set \u001b[0mand \u001b[1m80.23% for the testing set\u001b[0m\n",
      "\n",
      "\u001b[1mF1 score: \u001b[0m 0.306\n",
      "\u001b[1mAccuracy Score: \u001b[0m 80.23%\n",
      "\u001b[1mPrecision: \u001b[0m 0.572\n",
      "\u001b[1mRecall: \u001b[0m 0.209\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 58.40%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 58.40%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2276   98]\n",
      " [ 495  131]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88      2374\n",
      "           1       0.57      0.21      0.31       626\n",
      "\n",
      "    accuracy                           0.80      3000\n",
      "   macro avg       0.70      0.58      0.60      3000\n",
      "weighted avg       0.77      0.80      0.76      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine F1 score for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c66763",
   "metadata": {},
   "source": [
    "We tuned the \"C\" parameter for the logistic regression model. Although the model training is fast, the F1 score is lower at 0.306. The logistic regression model gave an accuracy of 81.49% for the training set, and 80.17% for the testing sets when using a \"C\" parameter of 10. We can see here that neither the training nor the testing score is high enough. This is because the model is not complex enough hence underfitting occurs. Let's see how other model behave before deciding on the model to use.\n",
    "\n",
    "#### AdaBoostClassifier\n",
    "AdaBoost is challenging to configure since the algorithm has many key hyperparameters that influence the behavior of the model on the training data, and the hyperparameters interact with each other. In such as senario, it is best practice to use a grid search process to discover a configuration of the model hyperparameters that works for the given problem. In this case, we would grid search two key parameters - the number of trees used in the ensemble and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c57e1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best F1 score is : \n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.569\n",
      "The accuracy of the model against the training data is: 0.581\n",
      "F1 score:  0.5604719764011798\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV Optimization for Adaboost\n",
    "# define the hyperparameter to tune\n",
    "grid = {\n",
    "    \"n_estimators\" : [10, 50, 100, 500],\n",
    "    \"learning_rate\" : [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "# define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the model\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, \n",
    "                           n_jobs=-1, cv=cv, scoring='f1')\n",
    "# execute the grid search\n",
    "grid_search.fit(features_train, target_train) \n",
    "y_pred = grid_search.predict(features_test)\n",
    "print('The parameters combination that would give best F1 score is : ')\n",
    "print(grid_search.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid_search.best_score_))\n",
    "print('The accuracy of the model against the training data is: {:.3f}'.format(grid_search.score(features_train, target_train)))\n",
    "print('F1 score: ', f1_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8365a4",
   "metadata": {},
   "source": [
    "We defined the grid search using k-fold cross-validation, and carried out grisearchcv optimization for the adaboost classifier. We looked for the configuration with the best score. We can see that the parameter configuration with 50 trees and a learning rate of 1.0 gave the best F1 score. We can use this figures as a guide to train and test the model or simply run a for loop through a set parameter values and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d716fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adaboost classifier\n",
    "def adaboost_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is an Adaboost classifier function developed to train\n",
    "    the model, make prediction on train and testing dataset, \n",
    "    and print F1 score and evaluation metrics for testing datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "    model = AdaBoostClassifier(**grid_search.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on testing set\n",
    "    ab_test_predictions = model.predict(X_test) \n",
    "    ab_test_predictions_acc = accuracy_score(y_test, ab_test_predictions)\n",
    "    test_scores.append(ab_test_predictions_acc)\n",
    "    f1_score_ = f1_score(y_test, ab_test_predictions)\n",
    "    f1_scores.append(f1_score_)\n",
    "    scores = list(zip(f1_scores, train_scores, test_scores))\n",
    "    print('The adaboost classifier had the best ' \"\\033[1m\" + \n",
    "          'F1 score of {:.3f} '.format(max(scores, key = lambda x: x[0])[0]) + \"\\033[0m\" + \n",
    "          'using' \"\\033[1m\" + ' n_estimate value of {},'.format(grid_search.best_params_['n_estimators']) + \"\\033[0m\" +\n",
    "          \"\\033[1m\" + ' learning rate of {}'.format(grid_search.best_params_['learning_rate']) + \"\\033[0m\" +\n",
    "          ' giving an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[0])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[2]) + ' for the testing set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate adaboost classifier metric\n",
    "    print_model_evaluation(target_test, ab_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cd86845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adaboost classifier had the best \u001b[1mF1 score of 0.560 \u001b[0musing\u001b[1m n_estimate value of 50,\u001b[0m\u001b[1m learning rate of 1.0\u001b[0m giving an accuracy of \u001b[1m86.13% for the training set \u001b[0mand \u001b[1m85.10% for the testing set\u001b[0m\n",
      "\n",
      "\u001b[1mF1 score: \u001b[0m 0.560\n",
      "\u001b[1mAccuracy Score: \u001b[0m 85.10%\n",
      "\u001b[1mPrecision: \u001b[0m 0.729\n",
      "\u001b[1mRecall: \u001b[0m 0.455\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 70.53%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 70.53%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2268  106]\n",
      " [ 341  285]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      2374\n",
      "           1       0.73      0.46      0.56       626\n",
      "\n",
      "    accuracy                           0.85      3000\n",
      "   macro avg       0.80      0.71      0.74      3000\n",
      "weighted avg       0.84      0.85      0.84      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine F1 score for adaboost classifier\n",
    "adaboost_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be860aab",
   "metadata": {},
   "source": [
    "We tuned the n_estimators and the learning rate for the AdaBoost classifier resulting in an F1 score of 0.56, accuracy of 86.23% for the training set, and 85.17% for the testing sets when using 50 trees and a learning rate of 1.0.\n",
    "\n",
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter optimization for Random Forest classifier\n",
    "# define the hyperparameter to tune\n",
    "parameters = {\n",
    "    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\" : [10, 50, 100, 200, 500],\n",
    "    \"max_depth\" : [None, 2, 4, 8, 10, 12, 16],\n",
    "    \"min_samples_split\" : [2, 4, 8, 16],\n",
    "    \"min_samples_leaf\" : [2, 4, 6]\n",
    "    }\n",
    "# define the model with default hyperparameters\n",
    "classifier = RandomForestClassifier()\n",
    "# define the grid search procedure\n",
    "grid_rf = GridSearchCV(estimator=classifier, param_grid=parameters, \n",
    "                    cv=5, scoring='f1')\n",
    "# execute the grid search\n",
    "grid_rf.fit(features_train, target_train) \n",
    "y_pred = grid_rf.predict(features_test)\n",
    "print('The parameters combination that would give best F1 score is : ')\n",
    "print(grid_rf.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid_rf.best_score_))\n",
    "print('The accuracy of the model against the training data is: {:.3f}'.format(grid_rf.score(features_train, target_train)))\n",
    "print('F1 score: ', f1_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b09e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random forest classifier model\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a random forest classifier function developed to train\n",
    "    the model, make prediction on train and testing dataset, \n",
    "    and print F1 score and evaluation metrics for testing datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "    model = RandomForestClassifier(**grid_rf.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on testing set\n",
    "    rf_test_predictions = model.predict(X_test) \n",
    "    rf_test_predictions_acc = accuracy_score(y_test, rf_test_predictions)\n",
    "    test_scores.append(rf_test_predictions_acc)\n",
    "    f1_score_ = f1_score(y_test, rf_test_predictions)\n",
    "    f1_scores.append(f1_score_)\n",
    "    scores = list(zip(f1_scores, train_scores, test_scores))\n",
    "    print('The random forest classifier had the best ' \"\\033[1m\" + \n",
    "          'F1 score of {:.3f} '.format(max(scores, key = lambda x: x[0])[0]) + \"\\033[0m\" + \n",
    "          'using' \"\\033[1m\" + ' n_estimate value of {},'.format(grid_rf.best_params_['n_estimators']) + \"\\033[0m\" +\n",
    "          \"\\033[1m\" + ' maximum tree depth of {}'.format(grid_rf.best_params_['max_depth']) + \"\\033[0m\" +\n",
    "          ' giving an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[0])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[2]) + ' for the test set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate random forest classifier metric\n",
    "    print_model_evaluation(target_test, rf_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0426bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy for random forest classifier\n",
    "random_forest_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe719c",
   "metadata": {},
   "source": [
    "We tuned the max_depth and n_estimators for the Random Forest classifier resulting in an F1 score of 0.54, accuracy of 89.76% for the training set, and 85.23% for the testing sets when using 16 trees and n_estimate value of 10.\n",
    "\n",
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edaa783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the CatBoost classifier model\n",
    "def catboost_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a catboost classifier function developed to train\n",
    "    the model, make prediction on train and testing dataset, \n",
    "    and print F1 score and evaluation metrics for testing datasets\n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = CatBoostClassifier(verbose=0, random_state=12345)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    # make predictions on testing set\n",
    "    cb_test_predictions = model.predict(X_test) \n",
    "    cb_test_predictions_acc = accuracy_score(y_test, cb_test_predictions)\n",
    "    f1_score_ = f1_score(y_test, cb_test_predictions)\n",
    "    print('The model has an ' \"\\033[1m\" 'F1 score of {:.3f},'.format(f1_score_) + \"\\033[0m\" +\n",
    "          ' accuracy of ' \"\\033[1m\" + '{:.2%}'.format(train_predictions_acc) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(cb_test_predictions_acc) + ' for the testing set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate catboost classifier metric\n",
    "    print_model_evaluation(target_test, cb_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12430c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine F1 score for CatBoost algorithm\n",
    "catboost_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169932d8",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "From the investigation of different model quality, we can see that the CatBoost classifier gives the best result for F1 score of 0.59, accuracy of 86.07% and AUC-ROC value of 71.85% of the five different models investigated. The logistic regression model had the lowest values for F1 score of 0.31, accuracy of 80.17%, and AUC-ROC of 58.36%. The Catboost model is the best model based on the F1 score when predicting whether a customer will leave the bank soon.\n",
    "\n",
    "## Check model quality\n",
    "#### Model testing\n",
    "The result of the previous section suggested that the CatBoost classifier was perhaps the most accurate model. Using the CatBoost classifier as our final model, we can make predictions using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the CatBoost classifier model\n",
    "def catboost_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a catboost classifier function developed to train\n",
    "    the model, make prediction on train and test dataset, print\n",
    "    model accuracy for training and test datasets and visualize\n",
    "    model accuracy scores on train and test sets\n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = CatBoostClassifier(verbose=0, random_state=12345)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    # make predictions on test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_predictions_acc = accuracy_score(y_test, test_predictions)\n",
    "    f1_score_ = f1_score(y_test, test_predictions)\n",
    "    print('The model has an ' \"\\033[1m\" 'F1 score of {:.3f},'.format(f1_score_) + \"\\033[0m\" +\n",
    "          ' accuracy of ' \"\\033[1m\" + '{:.2%}'.format(train_predictions_acc) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(test_predictions_acc) + ' for the test set' + \"\\033[0m\")\n",
    "    # plot of ROC and Precision-Recall curve\n",
    "    _, axs = plt.subplots(1, 2,figsize=(10,5))\n",
    "    axs = axs.ravel()\n",
    "    plot_pr(y_test, test_predictions, ax=axs[0], label=\"CatBoostClassifier\")\n",
    "    plot_roc(y_test, test_predictions, ax=axs[1], label=\"CatBoostClassifier\")\n",
    "    plt.title('Plot of ROC and Precision-Recall curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135013c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy for CatBoost algorithm\n",
    "catboost_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f030695",
   "metadata": {},
   "source": [
    "Using the CatBoost model, we obtained an F1-score of 0.59.\n",
    "\n",
    "## Overall conclusion\n",
    "In the first section, we downloaded and prepared the data. From the information about the dataset, we have 10000 rows and 14 features. Looking at the dataset, we observed that about 9% of the data is missing in the Tenure column, and the data is missing at random (MAR). We replaced the missing values, corrected the datatype, and encoded the categorical feature using one-hot encoding. We splitted the data into 70% training set, and 30% testing sets. Since the features have different scales, we standardized the numerical features of the data. The size of the new table is 7000 rows and 11 columns for the train features set, and 3000 rows and 11 columns for the test features set.\n",
    "\n",
    "We trained the model without taking into account the imbalance. We achieved a F1 score of 0.304. We assess the sanity of the model by checking how often the target feature contains the class \"1\" or \"0\". We observed the class imbalance in the dataset. Next we try to improve the quality of the model using two different approaches to fixing class imbalance. First, we split the training sample into negative and positive observations, we duplicated the positive observations and combine them with the negative class observation. Then we shuffled the data using shuffle() function, and trained our LogisticRegression model with the new data. We calculated the F1 score to be 0.487.\n",
    "\n",
    "We investigated several models and tuned different hyperparameters for those model using GridSearchCV and RepeatedStratifiedKFold. From the investigation of different model quality, we observed that the CatBoost classifier gave an accuracy of 91.26% for the training data, and 86.07% for the testing data which is the best result of the five different models investigated. The logistic regression model gave the lowest accuracy prediction of the five models with an accuracy of 80.17% for the testing sets. We proceed to use the CatBoost classifier to perform the final test prediction on the unseen test data. Using the CatBoost model, we obtained an F1-score of 0.59.\n",
    "\n",
    "At the end of this project, we were able to develop a model that can predict whether a customer will leave the bank soon with an accuracy of 86% and an F1-score of 0.59. The CatBoost model really helped the business predict whether customers will churn or not."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1135,
    "start_time": "2021-11-19T18:31:23.383Z"
   },
   {
    "duration": 151,
    "start_time": "2021-11-19T18:31:24.520Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-19T18:31:25.167Z"
   },
   {
    "duration": 105,
    "start_time": "2021-11-19T18:31:27.743Z"
   },
   {
    "duration": 13248,
    "start_time": "2021-11-19T18:31:32.405Z"
   },
   {
    "duration": 39,
    "start_time": "2021-11-19T18:31:45.655Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-19T18:34:54.077Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-19T18:34:55.016Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-19T18:34:56.169Z"
   },
   {
    "duration": 13,
    "start_time": "2021-11-19T18:34:58.854Z"
   },
   {
    "duration": 49,
    "start_time": "2021-11-19T18:34:59.809Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-19T18:35:32.748Z"
   },
   {
    "duration": 369,
    "start_time": "2021-11-19T18:36:25.486Z"
   },
   {
    "duration": 36,
    "start_time": "2021-11-19T18:40:00.809Z"
   },
   {
    "duration": 280,
    "start_time": "2021-11-19T18:41:34.127Z"
   },
   {
    "duration": 318,
    "start_time": "2021-11-19T18:41:45.712Z"
   },
   {
    "duration": 86,
    "start_time": "2021-11-19T18:42:00.664Z"
   },
   {
    "duration": 22,
    "start_time": "2021-11-19T18:46:36.379Z"
   },
   {
    "duration": 343,
    "start_time": "2021-11-19T18:46:37.135Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
