{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "df89053c-55da-4946-b602-c3baf619b53f"
    ]
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored in the `/datasets/faces/` folder, there you can find\n",
    "- The `final_files` folder with 7.6k photos\n",
    "- The `labels.csv` file with labels, with two columns: `file_name` and `real_age`\n",
    "\n",
    "Given the fact that the number of image files is rather high, it is advisable to avoid reading them all at once, which would greatly consume computational resources. We recommend you build a generator with the ImageDataGenerator generator. This method was explained in Chapter 3, Lesson 7 of this course.\n",
    "\n",
    "The label file can be loaded as an usual CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/datasets/faces/labels.csv')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory='/datasets/faces/final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check head of dataframe\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show labels information\n",
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of dataset\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive labels\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "From the initial look at the data, we can see that the data has 7591 rows and 2 columns. From the description of the data, we can see that the mean age is 31 years and the maximum age is 100 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images of different people and their ages\n",
    "features, target = next(train_gen_flow)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    fig.add_subplot(4, 4, i+1)\n",
    "    plt.imshow(features[i])\n",
    "    plt.title(target[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of ages\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.distplot(labels['real_age'], kde=True, bins=100, color='blue')\n",
    "plt.title('Distribution of age')\n",
    "plt.ylabel('Distribution')\n",
    "plt.xlabel('Real age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "We can see that the average age of customers to the store is around 30 years. Most people aged 17 - 41 years visited the store most often. There were less elderly people visiting the store. The high number of children aged 0 - 9 years that visited the store may be because some parents visited the store with their children."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the necessary functions to train your model on the GPU platform and build a single script containing all of them along with the initialization section.\n",
    "\n",
    "To make this task easier, you can define them in this notebook and run a ready code in the next section to automatically compose the script.\n",
    "\n",
    "The definitions below will be checked by project reviewers as well, so that they can understand how you built the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    \"\"\"\n",
    "    It loads the train part of dataset from path\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv('/datasets/faces/labels.csv')\n",
    "    # data generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rotation_range=90)\n",
    "\n",
    "    # extract data from the directory\n",
    "    train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory='/datasets/faces/final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='training',\n",
    "        seed=12345)\n",
    "\n",
    "    return train_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddef load_test(path):\n",
    "    \"\"\"\n",
    "    It loads the validation/test part of dataset from path\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv('/datasets/faces/labels.csv')\n",
    "    # validation data generator\n",
    "    test_datagen = ImageDataGenerator(validation_split=0.25, rescale=1/255)\n",
    "\n",
    "    # extract data from the directory\n",
    "    test_gen_flow = test_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory='/datasets/faces/final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='validation',\n",
    "        seed=12345)\n",
    "\n",
    "    return test_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \"\"\"\n",
    "    It defines the model\n",
    "    \"\"\"\n",
    "    backbone = ResNet50(\n",
    "        input_shape=input_shape, weights='imagenet', include_top=False\n",
    "    )\n",
    "\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # add layers to model\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(350, activation='relu'))\n",
    "    model.add(Dense(185, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # add compiler\n",
    "    optimizer = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse', metrics=['mae']\n",
    "                  )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    train_data, \n",
    "    test_data, \n",
    "    batch_size=None, \n",
    "    epochs=20,\n",
    "    steps_per_epoch=None, \n",
    "    validation_steps=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the model given the parameters\n",
    "    \"\"\"\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=10,\n",
    "        verbose=2,\n",
    "        batch_size=batch_size,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Script to Run on the GPU Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given you've defined the necessary functions you can compose a script for the GPU platform, download it via the \"File|Open...\" menu, and to upload it later for running on the GPU platform.\n",
    "\n",
    "N.B.: The script should include the initialization section as well. An example of this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a script to run on the GPU platform\n",
    "\n",
    "init_str = \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "with open('run_model_on_gpu.py', 'w') as f:\n",
    "    \n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "        \n",
    "    for fn_name in [load_train, load_test, create_model, train_model]:\n",
    "        \n",
    "        src = inspect.getsource(fn_name)\n",
    "        f.write(src)\n",
    "        f.write('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
